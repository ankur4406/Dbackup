{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting up by importing all the relevant libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import misc\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import csv\n",
    "\n",
    "# import json\n",
    "# import sklearn\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "# import nltk\n",
    "# import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "dir = r'C:\\Users\\ankuarora\\Desktop\\Client\\2017_05_CogEx\\2017_07_R2Implementation\\Sprint 7\\1CreateTrainData\\SampleForms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import all images (jpg, gif & png) in the directory as a list\n",
    "imgs = []\n",
    "valid_images = [\".jpg\",\".jpeg\",\".gif\",\".png\"]\n",
    "for f in os.listdir(dir):\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    imgs.append((f, cv2.imread(os.path.join(dir,f),0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of initial features that needs be extracted\n",
    "feature_list = ['width','height','seq_from_top','seq_from_bottom','width_prv',\n",
    "                'height_prv','width_nxt','height_nxt','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Parsing '2012ccf11ce565a8e1877fdc8eb9c9d7--sample-business-proposal-proposal-sample.jpg' ...\n",
      "2. Parsing '33a558d26a987dd4a0976ad0c1d9ab02--cover-letter-example-cover-letters.jpg' ...\n",
      "3. Parsing 'affiliation-sample-letter_80-0.png' ...\n",
      "4. Parsing 'Anna Thi Pan-Resume.jpg' ...\n",
      "5. Parsing 'Character-Reference-Sample-Letter-Template-Free-Download.jpg' ...\n",
      "6. Parsing 'College-Recommendation-Letter-Sample.jpeg' ...\n",
      "7. Parsing 'Example-Restaurant-Complaint-Letter.jpg' ...\n",
      "8. Parsing 'Free-Sample-Business-Complaint-Letter.jpg' ...\n",
      "9. Parsing 'letter-of-attestation-of-training-sample_93-0.png' ...\n",
      "10. Parsing 'letter-of-direction-sample_185-0.png' ...\n",
      "11. Parsing 'letter-of-donation-to-business-sample_195-4.png' ...\n",
      "12. Parsing 'letter-of-interest-24.jpg' ...\n",
      "13. Parsing 'letter-of-interest-26.jpg' ...\n",
      "14. Parsing 'Letter-of-Introduction-21.jpg' ...\n",
      "15. Parsing 'letter-of-justification-for-funding-sample_210-1.png' ...\n",
      "16. Parsing 'letter-of-promotion-to-employee-sample_268-0.png' ...\n",
      "17. Parsing 'Letter-of-Recommendation-for-Admission.jpg' ...\n",
      "18. Parsing 'letter-of-support-example.jpg' ...\n",
      "19. Parsing 'PA-SCHOOL-Letter-of-Reference-2-The-Physician-Assistant-Life.jpg' ...\n",
      "20. Parsing 'Sample-Application-Letter-by-Fresher.jpg' ...\n",
      "21. Parsing 'Sample-Application-Letter-for-Referral.jpg' ...\n",
      "22. Parsing 'Sample-Complaint-Letter-to-Landlord.jpg' ...\n",
      "23. Parsing 'Sample-Letter-for-Job-Transfer-For-Employee-Free-Download-min.jpg' ...\n",
      "24. Parsing 'sample-letter-of-adjustment_381-0.png' ...\n",
      "25. Parsing 'sample-letter-of-administration_65-1.png' ...\n",
      "26. Parsing 'Sample-Letter-of-Introduction.jpg' ...\n",
      "27. Parsing 'Sample-Letter-of-Recommendation2.jpg' ...\n",
      "28. Parsing 'Sample-Warning-Letter.jpg' ...\n",
      "29. Parsing 'veterans-day-sample-letter-2013-2-638.jpg' ...\n"
     ]
    }
   ],
   "source": [
    "# Loop through all images and slice the documents\n",
    "# Also, create the initial feature space\n",
    "features = pd.DataFrame(index=[], columns=feature_list)\n",
    "cnt = 0\n",
    "for img in imgs:\n",
    "    cnt+=1\n",
    "    print (str(cnt) + \". Parsing '\" + img[0] + \"' ...\")\n",
    "    \n",
    "    # Preprocess the image\n",
    "    image = cv2.threshold(img[1], 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # Remove the white borders, if any\n",
    "    p_image = cv2.bitwise_not(image)\n",
    "    coords = np.column_stack(np.where(p_image > 0))\n",
    "    x,y,w,h = cv2.boundingRect(coords)\n",
    "    image_sliced = image[np.max((x-10,0)) : np.min((x+w+10,image.shape[0])),\n",
    "                         np.max((y-10,0)) : np.min((y+h+10, image.shape[1]))]\n",
    "    \n",
    "    # Find lines by horizontally blurring the image and thresholding\n",
    "    blur = cv2.blur(image_sliced, (91,9))\n",
    "    b_mean = np.mean(blur, axis=1)/255\n",
    "    threshold = np.percentile(b_mean, 50)\n",
    "    t = b_mean > threshold\n",
    "    byte_lines = np.where(1-t)\n",
    "    byte_lines = byte_lines[0]\n",
    "    \n",
    "    # Calculate the median linespace value for defining sections \n",
    "    linspace = []\n",
    "    for x in range(byte_lines.shape[0]-1):\n",
    "        if byte_lines[x+1] == byte_lines[x] + 1:\n",
    "            continue\n",
    "        linspace.append(byte_lines[x+1]-byte_lines[x]-1)\n",
    "    linspace_limit = (1.0 * np.median(linspace))\n",
    "\n",
    "    # Add in extra byte lines to cover unwanted linespace\n",
    "    for x in range(byte_lines.shape[0]-1):\n",
    "        if byte_lines[x+1] == byte_lines[x] + 1:\n",
    "            continue\n",
    "        if ((byte_lines[x+1]-byte_lines[x]) <= linspace_limit):\n",
    "            for i in range(byte_lines[x+1]-byte_lines[x]-1):\n",
    "                byte_lines = np.append(byte_lines, (byte_lines[x]+i+1))\n",
    "    byte_lines = np.sort(byte_lines)\n",
    "\n",
    "    # Identify text line coordinates (y) based on byte lines\n",
    "    txt_lines_y = []\n",
    "    start_y = byte_lines[0]\n",
    "    for y in range(1, byte_lines.shape[0]-1):\n",
    "        if byte_lines[y] == byte_lines[y-1] + 1:\n",
    "            continue\n",
    "        # identified gap between lines, close previous line and start a new one\n",
    "        end_y = byte_lines[y-1]\n",
    "        txt_lines_y.append([start_y, end_y])\n",
    "        start_y = byte_lines[y]\n",
    "    end_y = byte_lines[-1]\n",
    "    txt_lines_y.append([start_y, end_y])\n",
    "\n",
    "    # Identify text line coordinates (x) based on non blank columns\n",
    "    txt_lines_x = []\n",
    "    for line in txt_lines_y:\n",
    "        xx = []\n",
    "        for x in range(image_sliced.shape[1]):\n",
    "            col = image_sliced[line[0]:line[1], x]\n",
    "            if np.min(col) < 128:\n",
    "                xx.append(x)\n",
    "        txt_lines_x.append([min(xx), max(xx)])\n",
    "\n",
    "    # Slice the document based on the coordinates and perform OCR. \n",
    "    # Also, create basic features for use in learning.\n",
    "    for i in range(len(txt_lines_x)):\n",
    "        slc = image_sliced[np.max((txt_lines_y[i][0] - 2,0)) : np.min((txt_lines_y[i][1] + 2,image.shape[0])), \n",
    "                           np.max((txt_lines_x[i][0] - 2,0)) : np.min((txt_lines_x[i][1] + 2,image.shape[1]))]\n",
    "        filename = os.path.splitext(img[0])[0] + '_slice' + str(i+1) + os.path.splitext(img[0])[1]\n",
    "        misc.imsave(os.path.join(dir, \"slices\\\\\" + filename), slc)\n",
    "        ocr_txt = pytesseract.image_to_string(Image.open(os.path.join(dir, \"slices\\\\\" + filename)))\n",
    "        # os.remove(filename)\n",
    "        features.loc[filename] = [(txt_lines_x[i][1] - txt_lines_x[i][0] + 4)/image_sliced.shape[1],\n",
    "                                  (txt_lines_y[i][1] - txt_lines_y[i][0] + 4)/image_sliced.shape[0],\n",
    "                                  (i+1),\n",
    "                                  (len(txt_lines_y)-i),\n",
    "                                  0 if not i else (txt_lines_x[i-1][1] - txt_lines_x[i-1][0] + 4)/image_sliced.shape[1],\n",
    "                                  0 if not i else (txt_lines_y[i-1][1] - txt_lines_y[i-1][0] + 4)/image_sliced.shape[0],\n",
    "                                  0 if i==len(txt_lines_x)-1 else (txt_lines_x[i+1][1] - txt_lines_x[i+1][0] + 4)/image_sliced.shape[1],\n",
    "                                  0 if i==len(txt_lines_y)-1 else (txt_lines_y[i+1][1] - txt_lines_y[i+1][0] + 4)/image_sliced.shape[0],\n",
    "                                  ocr_txt.lower()\n",
    "                                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export slice names for manual annotation\n",
    "with open(os.path.join(dir, 'slices\\\\slice_list.csv'), 'w') as csvfile:\n",
    "    wr = csv.writer(csvfile, quoting=csv.QUOTE_ALL, delimiter='\\n')\n",
    "    wr.writerow(features.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice list & features json created successfully\n"
     ]
    }
   ],
   "source": [
    "# Dump the features list as csv for use in subsequent modules\n",
    "features.to_csv('features_raw.csv')\n",
    "\n",
    "print (\"Slice list & features json created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
